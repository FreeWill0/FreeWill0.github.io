---
layout:     post
title:      NFM
subtitle:   03
date:       2021-3-25
author:     JieKun Liu
header-img: img/the-first.png
catalog:   true
tags:
    - Recommender System
---
## 概述
---

在CTR预估中，为了解决稀疏特征的问题，学者们提出了FM模型来建模特征之间的交互关系

但是FM模型只能表达特征之间两两组合之间的关系，无法建模两个特征之间深层次的关系或者说多个特征之间的交互关系，

因此学者们通过Deep Network来建模更高阶的特征之间的关系

FM模型用n个隐变量来刻画特征之间的交互关系

这里要强调的一点是，n是特征的总数，是one-hot展开之后的，

比如有三组特征，两个连续特征，一个离散特征有5个取值，那么n=7而不是n=3.

Embedding Layer和我们之间几个网络是一样的，embedding 得到的vector其实就是我们在FM中要学习的隐变量v

Bi-Interaction Layer名字挺高大上的，其实它就是计算FM中的二次项的过程，因此得到的向量维度就是我们的Embedding的维度

Hidden Layers就是我们的DNN部分，将Bi-Interaction Layer得到的结果接入多层的神经网络进行训练，从而捕捉到特征之间复杂的非线性关系。

## 心得

NFM模型将FM与神经网络结合以提升FM捕捉特征间多阶交互信息的能力。根据论文中实验结果，NFM的预测准确度相较FM有明显提升，并且与现有的并行神经网络模型相比，复杂度更低。

NFM本质上还是基于FM，FM会让一个特征固定一个特定的向量，当这个特征与其他特征做交叉时，都是用同样的向量去做计算

这个是很不合理的，因为不同的特征之间的交叉，重要程度是不一样的。

因此，学者们提出了AFM模型（Attentional factorization machines），将attention机制加入到我们的模型中
