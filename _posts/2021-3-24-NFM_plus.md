---
layout:     post
title:      NFM
subtitle:   02
date:       2021-3-24
author:     JieKun Liu
header-img: img/the-first.png
catalog:   true
tags:
    - Recommender System
---
## 概述
矩阵分解是一种基于协作的过滤方法，用于推荐系统。与推荐器系统中的其他方法一样，典型的输入是用户项交互，该交互可以存储在矩阵中，

每行代表每个用户，每个列都专门用于每个项目。

由于不是每个用户都在对每个项目进行评分，所以用户项交互矩阵将是稀疏的。因此，矩阵分解方法的目标是预测缺失项。

为了预测缺失项，将主矩阵分解为二维低维矩阵的乘积。第一个矩阵与主矩阵的行数相同，每行属于每个人，而第二个矩阵为每个项目都有一列。

矩阵中的每一个都表示用户或项目之间具有潜在因素或隐藏特征之间的关联能力。

潜在因素的数量可能会有所不同。随着所选潜在因素的增加，从数据中提取出更多的隐藏因子，从而提高推荐系统的质量。

然而，在某些情况下，潜在因素的数量过多会导致数据拟合过度，从而降低推荐质量。
￼
￼
我们意识到，通过P和Q，

我们可以用缺失输入的估计值来近似矩阵R。

现在，问题是如何得到P和Q矩阵。这里可以使用的一个著名的优化算法是梯度下降法。

在该算法中，P和Q的初始值应为随机值。然后在每次迭代中计算P和Q的乘积，看看它与原始矩阵R有什么不同。

如果它们的乘积接近R，我们就停止迭代，否则P和Q的值应该以最小化这种差异的方式改变。

这个过程继续进行，直到在近似矩阵和实际矩阵之间达到估计误差的局部最小值。

## 心得
α被称为学习速率，它决定了接近最小值的速率。

α不应该选得太高，因为过高的学习率会朝着最小值迈出更大的一步，并可能失去它，最终在最小值附近波动。

另一方面，太低的学习率会花费太长的时间来收敛，或者陷入一个不理想的局部极小值。

使用上面的更新规则，我们可以重复操作，直到整个错误最小化，并指定何时停止进程。

最后，用优化过程得到的简单积P和Q来逼近原矩阵的缺失项。

在上述场景中需要考虑的一个重要问题是矩阵P和Q是非负的，因此这种方法被称为非负因式分解。

